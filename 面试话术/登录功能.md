## 登录

#### Cookie

* 是服务器发送到浏览器（响应里面有个setcookie属性），并保存在浏览器端的一小块数据，比如用户名
* 浏览器下次访问该服务器时，会**自动**携带块该数据，将其发送给服务器
* 客户端，默认4kb太小，安全风险容易篡改，浏览器也可能禁用cookie

#### Session

* 服务器响应里面有个setcookie属性，设置为sessionId，后面在请求的时候会自动添加sessionId

登录问题：

* 首先登录模块主要是web端和小程序端的；共用一套后端；都是实现redis保存token、图片验证码和手机验证码登录的功能，并且在这个基础上进行限流。如何使用redis保存呢，登录有用户名，密码，图片验证码；和手机号、手机验证码、图片验证码两种，redis主要是保存这两个验证码，先说第一种用户名登录的情况，当访问登陆页面，后端生成图片验证码，保存到redis里面（string类型，用生成的UUID作为key来命名，同时这个key放到cookie里面并设置cookie有效期1分钟），同时返回给前端，前端输入用户名密码和验证码后提交表单，后端接收后，首先看刚刚保存在cookie里面的key有没有过期，然后在redis里面获取这个key的值，进行比较看验证码是否正确；如果正确之后，再从数据库里面比较用户名和密码，这里的密码使用了随机盐加MD5加密的方式存储；至于手机验证码登录，同样是存入redis里面，进行比较。
* 需要注意的是，图片验证码是可以重复刷新的，手机验证码要隔一分钟，这里采用的是redis里面的set nx命令，如果key存在，没过期的话，就不能发送。如果redis出现问题没有存的话，比较两次生成的时间。**再不济放入mysql中**
* **问题：**如果出现存入redis失败的情况；这个时候可以把验证码存入mysql，或者让用户可以重新尝试发一次。
* 怎么维护登陆状态，一开始是使用一张表login_ticket记录是否处于登录状态，有一个字段为status，登陆的时候将状态设为1，退出登录就设置为0；在这个登录基础上，将登录凭证对象存到redis里面（String类型），key是随机生成的UUID，定义为凭证ID，value就是登陆凭证对象；这里设置过期时间比较长，因为会对商户每天登陆的情况进行奖励，如果之前的记录删除了，就不好统计了；同时在cookie里面设置ticket属性，存的是刚刚随机生成的UUID。同时配置相关的拦截器，这样每次访问的时候都可以在拦截器中，获取cookie里面的凭证ID，在拦截器中检查凭证对象是否有效，如果有效的话，再查userId，然后在hostHolder里面持有该用户。HostHolder用于多线程环境下，持有用户信息。

#### 限制登陆问题

* 检查账号密码是否频繁登录，需要借助redis的zset数据结构，设计一个时间窗口限流算法实现（登录，点赞，评论等），进行限流，避免对数据库造成压力
* 窗口限流：定义一个窗口和登录限制次数；
* 当用户每次发生限流行为，都会记录这个行为，以 Redis zset的方式进行记录
* 调用redis的zcount（ZCOUNT key min max）命令，这个命令可以传入起始分值和结束分值。key是用户id，score是时间戳。我就把当前时间戳作为结束分值，然后当前时间戳减去限流时间，比如说15分钟的窗口，登录次数就是这15分钟的记录次数；如果超过15就限流，不发验证码给客户端，暂时不能登录

#### 查询问题：

* 查询货品，进货的时候一般是凌晨三四点，而且是很多商家一起，同一时间段都从供应商那边进货。考虑到mysql查询压力，避免缓存穿透，提前将前一周销量比较大的货品放到布隆过滤器预热，后面查询的时候可以直接从布隆过滤器中查询，如果查询没有，说明不是热点数据
* sql方面，优化sql查询，避免使用select *  ；子查询等，合理使用索引，避免索引失效（最左匹配原则），避免like查询左边有%

#### Lua 脚本

* 判断兑换礼品库存是否充足且一人只能兑换一次
* 在lua脚本中编写多条Redis命令，redis会将整个脚本作为一个整体执行，中间不会被其他请求打断
* 当redis同时收到多个请求时，由于Redis 命令的执行采用的是单线程模型，它会一个一个的去执行当前lua脚本（放在一个队列里面），其他的请求就会阻塞。（Redis不会进行回滚，aof和RDB持久化）
* 这里采用的redis服务器是一主多从的，如果是多主多从就不能保证原子性了
* 使用分布式锁，set nx  set ex，防止同一用户进行多次操作
* 兑换逻辑：

#### 定时传输

* 涉及到数据安全的问题，每天定时传输数据库数据到静安服务器，使用的是Spring Schedule

* 1.开启定时任务注解  @EnableSchedule
  2.设置执行时间  @Scheduled(cron表达式)
  
* fixedDelay设置的是：上一个任务结束后多久执行下一个任务；

  fixedRate设置的是：上一个任务的开始到下一个任务开始时间的间隔；

  如果是强调任务间隔的定时任务，建议使用fixedRate和fixedDelay，如果是强调任务在某时某分某刻执行的定时任务，建议使用cron表达式。

  处理方式是等待上一个任务执行完成后，再去执行下一个任务
  
* ```txt
  常用cron表达式介绍
  秒 分 小时 日 月 星期
  0 0 0 * * ?     每天0点一次
  0 0 23 * * ?    每天23点一次
  O */1 * * * ?   每1分钟(每个1分钟的整数倍)
  0 0 */6 * * ?        每6小时(每个6小时的整数倍)
  0 0 */1 * * ?        每1小时(每个1小时的整数倍)
  0 0 9-22/4 * * ？     在9-22点之间每隔4小时执行
  ```
  
* **问题：默认是单线程的定时任务，如果任务持续时间较长，就会将后续定时任务拖延，导致丢失任务。**

* 实现异步多线程：开启异步注解（@EnableAsync），设置异步执行（@Async），让任务分别运行在不同的scheduler里

* 下面是`@Scheduled`注解的执行流程：
  
  1. **扫描注解：** Spring在应用启动时扫描带有`@Scheduled`注解的方法。
  2. **解析注解：** Spring解析这些注解，确定每个被注解的方法应该在什么时间执行。
  3. **创建调度任务：** Spring为每个被注解的方法创建一个独立的调度任务。这些任务可以由Spring的任务执行器（TaskExecutor）来执行，通常情况下，默认会使用一个单线程的任务执行器。
  4. **执行任务：** 当时间到达指定的执行时间，任务执行器会调用相应的方法执行。
  5. **异常处理：** 如果被调度的方法抛出了异常，Spring会捕获这些异常并根据配置进行处理。可以通过配置`@Scheduled`注解的`exceptionHandler`属性来指定异常处理策略。
  6. **重复执行：** 如果方法被配置为重复执行（例如使用`fixedRate`或`fixedDelay`属性），则在每次执行完成后，Spring会根据配置决定何时再次执行该方法。
  
* Spring Task 底层是基于 JDK 的 `ScheduledThreadPoolExecutor` 线程池来实现的

* `ScheduledThreadPoolExecutor` 本身就是一个线程池，继承于ThreadPoolExecutor类，支持任务并发执行。并且，其内部使用 `DelayedWorkQueue` 作为任务队列。通常用于实现定时任务调度或者延迟任务执行的功能

* Spring 自带的定时调度只支持单机，并且提供的功能比较单一

#### 文件上传

* 压缩，分块，多线程，断点续传

* 在网络传输中，文件大小可能会很大，如果直接将整个文件传输，会占用大量带宽和时间。为了更高效地传输大文件，可以将文件分成多个块，使用多线程同时传输这些块，以加快传输速度。

* 1.将文件分成多个块；按照大小分块

* 2.创建多个线程，每个线程负责传输一个块，进行上传

* 3.线程传输完成后，将块重新合并成完整文件

* **实现文件断点续传**：基于文件分块，可以实现`上传的暂停`，即中断正在上传的请求，服务器会`保存已经上传的分块`，可以记录这些分块的 hash 值，然后客户端下次上传时，服务器会告诉客户端还有哪些分块未上传（或者哪些分块已上传），客户端只要`上传未上传的分块`就可以了，不用从头开始上传。

* 确定你要实现的是大文件上传，还是小文件上传，像 20 M 以下都算比较小的文件，基本可以采用单个请求来发送整个文件，如果失败重试即可。

  上传大文件由于用户网络的不确定性，我们需要考虑将文件进行分片处理，另外发送多个请求使用到了多线程，能大大提高上传的效率。

  使用到分片后，我们需要在服务端将这些分片文件合并成一个完整的文件，由于我们不能保证分片上传的有序性，所以需要给每个分片设置一个唯一标识，这里可以使用分片的 hash 值作为分片的唯一标识。（我使用的是每个分片在文件中的索引，这个要方便一些，但安全性要更差，也验证不了文件的完整性）

  分片文件的上传就引出了一个新的问题（解决问题会产生问题😂），同时上传这些分片会导致客户端卡顿，也会消耗服务端的线程资源。如果文件非常大，上传时间非常长，会导致浏览器卡顿甚至未响应，对服务端也会造成压力。所以我们需要创建一个请求队列，限制最大请求数量，达到最大的请求任务数量时，其他的任务等待正在执行的任务执行完毕。

  由于大文件上传使用分片上传，每个分片的上传，我们都可以给它中断，所以这里就可以设置一个暂停的功能，手动中断请求，清空请求队列。这时客户端和服务端都保存着上传记录。客户端点击开始上传，会从上次的上传位置继续上传。

  当所有文件分片上传完成后，通知服务端合并文件，或者在上传文件分片前告诉服务端有多少个分片，让服务端在所有分片上传之后自动合并文件。合并后删除所有分片文件。
  


1、检验账号：web端账号密码、小程序是手机验证码

前后端分离的项目，数据以JSON 的方式进行请求和响应，当收到请求的时候，会校验账号和密码以及验证码参数；

* 首先前端检验参数是否合法（手机号码是否11位，密码格式），是否非空；失败就直接返回失败信息，重新回到登陆页面
* 手机验证码可以限制次数，比如一分钟一次，使用set ex或者set nx过期时间，检验验证码是否正确，在redist里面存的验证码和用户比对， 
* 参数没问题的话，检查账号密码是否频繁登录，需要借助redis的zset数据结构，设计一个时间窗口限流算法实现（登录，点赞，评论等），进行限流，避免对数据库造成压力
* 如果没有限流，就查询用户数据，检查是否存在，并进行密码校验，这里检验密码的时候，使用了一个随机盐的一个工具类BCrypt实现，安全度较高

2、前后端测试： Postman  可以创建团队，把接口写好了之后放在团队里面

3、调用ES进行搜索，为什么不用mysql，主要是模糊查询，容易不走索引，查询效率很低，需要随机IO，性能比较低；ES可以进行分词索引，只需将信息放进ES服务器中，查询时可以返回需要的内容

4、ThreadLocal:保存用户线程信息，后续的controller，sevice 就可以随时随地获取用户信息

5、部署项目：

６、SQL查询并优化

７、实现方式很简单，我们提前购买了IP 地址数据的省级离线库 ® https://user.ip138.com/ip/lib/我们是在发布的时候，从请求头中获取到客户端IP 地址信息，然后查询数据库中的数据，得到发布的地点，随着文章或评论一起保存到数据库表中就可以了。

8、Single Sign-O ： 单点登录，允许用户只需要一次登录就能够访问多个独立的应用程序或系统。

通常情况下，一个用户需要为每个应用程序或系统提供不同的用户名和密码进行登录。然而，使用SSO，用户只需在一个集中的身份认证系统中登录一次，该系统会提供一个令牌（token）给用户，表示用户已经通过身份验证。然后，用户可以使用这个令牌来访问其他受信任的应用程序或系统，而不需要再次提供用户名和密码。

